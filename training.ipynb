{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "In this notebook, we will train the YOLOv8 models (any variant YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l etc.) on the custom dataset that contains 21k annotated images of dangerous objects.\n",
    "\n",
    "Before starting, make sure to download this custom dataset from here: https://universe.roboflow.com/startup-zn0ol/dangerous-objects-dq94u\n",
    "\n",
    "> Note: You can use any dataset of your choice, but make sure to update the paths in the code below.\n",
    "\n",
    "Verify and update the `data.yaml` file with the new classes and paths to the training and validation datasets. Make sure to put the `dangerous-objects` folder in the `datasets/` directory.\n",
    "\n",
    "\n",
    "```yaml\n",
    "# Dataset paths\n",
    "train: dangerous-objects/train/images\n",
    "val: dangerous-objects/valid/images\n",
    "test: dangerous-objects/test/images\n",
    "\n",
    "# Number of classes\n",
    "nc: 6\n",
    "\n",
    "# Class names\n",
    "names: ['ammo', 'firearm', 'grenade', 'knife', 'pistol', 'rocket']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "## Clear notebook output\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set up Comet.ml to log experiment data\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "load_dotenv()\n",
    "          \n",
    "experiment = Experiment(\n",
    "  api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "  project_name=\"enhancing-home-security\", # any name you like\n",
    "  workspace=\"chiragagg5k\" # your comet.ml workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model\n",
    "model_name = \"yolov8n\"\n",
    "model = YOLO(\n",
    "    f\"{model_name}.yaml\"\n",
    ") # or yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "\n",
    "# If cuda is available\n",
    "if(torch.cuda.is_available()):\n",
    "    print(\"Using GPU\")\n",
    "    model = model.to(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.93 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.90 ðŸš€ Python-3.11.4 torch-2.4.0 MPS (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=data.yaml, epochs=300, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/chiragagg5k/general/58fbd80fa5d6468485e8dc1b0ad62fe1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/labels... 18855 images, 34 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18855/18855 [00:03<00:00, 5359.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/55a3b54b-Knife_57_jpeg.rf.c9e10f81f50f22f49e34ff51a1f3f63f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/8ab3f5ea-png-transparent-brass-bullets-beside-black-pistol-firearm-bullet-weapo_j2kuPoH_png.rf.2f3953a7ecf9d14c6c0b1b1a7867ea32.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/8ab3f5ea-png-transparent-brass-bullets-beside-black-pistol-firearm-bullet-weapo_j2kuPoH_png.rf.8d9a2b7f54a620a156d113b8bbaffd1c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/8ab3f5ea-png-transparent-brass-bullets-beside-black-pistol-firearm-bullet-weapo_j2kuPoH_png.rf.b3a136d7c1ff7deebd26e21c6c7c9f40.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/e54811b7-387_jpg.rf.4461bfffc327d3c076dab02b7c491a68.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/e54811b7-387_jpg.rf.73f3b49dec9f9095a8871870cd958a55.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/images/e54811b7-387_jpg.rf.dfc79eec7fd5c38cb5dc56ffab33e969.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/chiragagg5k/Desktop/Coding_Stuff/Enhancing-Home-Security/datasets/dangerous-objects/valid/labels.cache... 1749 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1749/1749 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300         0G      3.548      4.469      4.202         61        640:   0%|          | 1/1179 [00:39<12:46:12, 39.03s/it]"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"data.yaml\", epochs=300, imgsz=640, verbose=True, plots=True, device='mps') # device = 0 for cpu, 1 for gpu, mps for apple silicon\n",
    "\n",
    "# Exit the logger\n",
    "experiment.log_artifact(f\"models/{model_name}_threat_detection.pt\")\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
